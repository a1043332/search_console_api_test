[
{'rows': [{'ctr': 0.14285714285714285, 'keys': ['you architect a system to analyze seismic data. your extract, transform, and load (etl) process runs as a series of mapreduce jobs on an apache hadoop cluster. the etl process takes days to process a data set because some steps are computationally expensive. then you discover that a sensor calibration step has been omitted. how should you change your etl process to carry out sensor calibration systematically in the future?'], 'position': 8.142857142857142, 'impressions': 7, 'clicks': 1}, {'ctr': 0.3333333333333333, 'keys': ['you used cloud dataprep to create a recipe on a sample of data in a bigquery table. you want to reuse this recipe on a daily upload of data with the same schema, after the load job with variable execution time completes. what should you do?'], 'position': 10.333333333333334, 'impressions': 3, 'clicks': 1}, {'ctr': 0, 'keys': ['250,000 devices produce a json device status every 10 seconds. how do you capture event data for outlier time series analysis?'], 'position': 13.4, 'impressions': 5, 'clicks': 0}, {'ctr': 0, 'keys': ['bigquery slot utilization'], 'position': 81, 'impressions': 2, 'clicks': 0}, {'ctr': 0, 'keys': ['bigquery table_date_range'], 'position': 83, 'impressions': 1, 'clicks': 0}, {'ctr': 0, 'keys': ['bigquerycreateexternaltableoperator'], 'position': 21, 'impressions': 3, 'clicks': 0}, {'ctr': 0, 'keys': ['dataproc gcs slow'], 'position': 71, 'impressions': 2, 'clicks': 0}, {'ctr': 0, 'keys': ['dataprocsparkoperator'], 'position': 43.5, 'impressions': 2, 'clicks': 0}, {'ctr': 0, 'keys': ['host a deep neural network machine learning model on gcp. run and monitor jobs that could occasionally fail.'], 'position': 8.5, 'impressions': 2, 'clicks': 0}, {'ctr': 0, 'keys': ['storage of json files with occasionally changing schema, for ansi sql queries.'], 'position': 19, 'impressions': 1, 'clicks': 0}], 'responseAggregationType': 'byProperty'}
